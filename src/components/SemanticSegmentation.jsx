import { useEffect, useRef, useState } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as semanticSegmentation from '@tensorflow-models/deeplab';
import { PASCAL_CLASSES } from '../constants/segmentationClasses';
import { useSegmentationRenderer } from '../hooks/useSegmentationRenderer';
import { useCamera } from '../hooks/useCamera';
import { useFPS } from '../hooks/useFPS';

const SemanticSegmentation = () => {
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const [model, setModel] = useState(null);
    const [loading, setLoading] = useState(true);
    const [isPortrait, setIsPortrait] = useState(window.innerHeight > window.innerWidth);
    const [selectedClass, setSelectedClass] = useState(null);
    const [detectedClasses, setDetectedClasses] = useState([]);
    
    const { fps, updateFPS } = useFPS();
    const { setupCamera } = useCamera(videoRef);
    const { renderSegmentation } = useSegmentationRenderer(canvasRef);

    // ç›‘å¬å±å¹•æ–¹å‘å˜åŒ–
    useEffect(() => {
        const handleOrientationChange = () => {
            setIsPortrait(window.innerHeight > window.innerWidth);
        };
        
        window.addEventListener('resize', handleOrientationChange);
        return () => {
            window.removeEventListener('resize', handleOrientationChange);
        };
    }, []);

    // åˆå§‹åŒ–æ¨¡å‹
    const loadModel = async () => {
        try {
            await tf.ready();
            await tf.setBackend('webgl');
            
            const model = await semanticSegmentation.load({
                base: 'pascal',
                quantizationBytes: 2
            });
            
            setModel(model);
            setLoading(false);
        } catch (error) {
            console.error('æ¨¡å‹åŠ è½½å¤±è´¥:', error);
            setLoading(false);
        }
    };

    // æ‰§è¡Œè¯­ä¹‰åˆ†å‰²
    const processFrame = async () => {
        if (!model || !videoRef.current || !canvasRef.current) return;

        try {
            const video = videoRef.current;
            const canvas = canvasRef.current;

            if (video.readyState < 2) return;

            // æ‰§è¡Œåˆ†å‰²
            const segmentation = await model.segment(video);
            
            // æ›´æ–°æ£€æµ‹åˆ°çš„ç±»åˆ«
            const detected = findDetectedClasses(segmentation);
            if (detected.length > 0) {
                setDetectedClasses(detected);
            }
            
            // æ¸²æŸ“åˆ†å‰²ç»“æœï¼Œæ ¹æ®selectedClassè¿‡æ»¤
            await renderSegmentation(video, segmentation, PASCAL_CLASSES, selectedClass);
            
            // æ›´æ–°FPS
            updateFPS();
            
            // æ¸…ç†èµ„æº
            if (segmentation.segmentationMap instanceof tf.Tensor) {
                tf.dispose(segmentation.segmentationMap);
            }
            
            // ç»§ç»­ä¸‹ä¸€å¸§
            requestAnimationFrame(processFrame);
        } catch (error) {
            console.error('åˆ†å‰²è¿‡ç¨‹å‡ºé”™:', error);
        }
    };
    
    // æ‰¾å‡ºæ£€æµ‹åˆ°çš„ç±»åˆ«
    const findDetectedClasses = (segmentation) => {
        const detectedIds = new Set();
        
        if (!segmentation || !segmentation.segmentationMap) {
            return [];
        }
        
        try {
            // è·å–åˆ†å‰²å›¾ä¸­çš„å”¯ä¸€ç±»åˆ«ID
            // å°è¯•ç›´æ¥è®¿é—®åº•å±‚æ•°æ®ï¼Œå¤„ç†ä¸åŒå½¢å¼çš„segmentationMap
            let segmentationData;
            
            if (segmentation.segmentationMap instanceof tf.Tensor) {
                // å¦‚æœæ˜¯TensorFlow.jså¼ é‡
                segmentationData = segmentation.segmentationMap.arraySync ? 
                    segmentation.segmentationMap.arraySync() : 
                    Array.from(segmentation.segmentationMap.dataSync());
            } else if (Array.isArray(segmentation.segmentationMap)) {
                // å¦‚æœæ˜¯æ™®é€šæ•°ç»„
                segmentationData = segmentation.segmentationMap;
            } else {
                // å¦‚æœæ˜¯TypedArray
                segmentationData = Array.from(segmentation.segmentationMap);
            }
            
            // å¤„ç†ä¸€ç»´æˆ–äºŒç»´æ•°ç»„
            if (Array.isArray(segmentationData)) {
                if (Array.isArray(segmentationData[0])) {
                    // äºŒç»´æ•°ç»„
                    for (let i = 0; i < segmentationData.length; i++) {
                        for (let j = 0; j < segmentationData[i].length; j++) {
                            const classId = segmentationData[i][j];
                            if (classId > 0) { // 0 æ˜¯èƒŒæ™¯
                                detectedIds.add(classId);
                            }
                        }
                    }
                } else {
                    // ä¸€ç»´æ•°ç»„
                    for (let i = 0; i < segmentationData.length; i++) {
                        const classId = segmentationData[i];
                        if (classId > 0) { // 0 æ˜¯èƒŒæ™¯
                            detectedIds.add(classId);
                        }
                    }
                }
            }
        } catch (error) {
            console.error('è§£æåˆ†å‰²æ•°æ®å‡ºé”™:', error);
        }
        
        // è½¬æ¢ä¸ºç±»åˆ«å¯¹è±¡æ•°ç»„
        return Array.from(detectedIds).map(id => {
            const className = PASCAL_CLASSES[id] ? PASCAL_CLASSES[id].name : 'æœªçŸ¥';
            return { id, name: className };
        });
    };
    
    // åˆ‡æ¢æ˜¾ç¤ºç‰¹å®šç±»åˆ«
    const toggleClass = (classId) => {
        if (selectedClass === classId) {
            setSelectedClass(null); // å†æ¬¡ç‚¹å‡»å–æ¶ˆç­›é€‰
        } else {
            setSelectedClass(classId);
        }
    };

    // å¯åŠ¨åˆ†å‰²è¿‡ç¨‹
    const startSegmentation = async () => {
        if (await setupCamera()) {
            processFrame();
        }
    };

    useEffect(() => {
        loadModel();
    }, []);

    useEffect(() => {
        if (model) {
            startSegmentation();
        }
    }, [model]);

    return (
        <div className="segmentation-container">
            {isPortrait && (
                <div className="orientation-warning">
                    <div className="orientation-content">
                        <div className="orientation-icon">ğŸ“±</div>
                        <p>å»ºè®®æ¨ªå±ä½¿ç”¨<br/>ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒ</p>
                        <div className="rotate-icon">ğŸ”„</div>
                    </div>
                </div>
            )}
            
            {loading && (
                <div className="loading">
                    <p>è¯­ä¹‰åˆ†å‰²æ¨¡å‹åŠ è½½ä¸­</p>
                </div>
            )}
            
            <div className="video-container">
                <video
                    ref={videoRef}
                    width="640"
                    height="480"
                    playsInline
                    autoPlay
                    style={{ display: 'none' }}
                />
                <canvas
                    ref={canvasRef}
                    width="640"
                    height="480"
                />
            </div>
            
            <div className="fps-display">
                FPS: {fps}
            </div>
            
            {detectedClasses.length > 0 && (
                <div className="detected-classes">
                    <h3>æ£€æµ‹åˆ°çš„ç‰©ä½“:</h3>
                    <div className="class-tags">
                        {detectedClasses.map(cls => (
                            <button 
                                key={cls.id}
                                className={`class-tag ${selectedClass === cls.id ? 'active' : ''}`}
                                onClick={() => toggleClass(cls.id)}
                            >
                                {cls.name}
                            </button>
                        ))}
                    </div>
                </div>
            )}
        </div>
    );
};

export default SemanticSegmentation; 